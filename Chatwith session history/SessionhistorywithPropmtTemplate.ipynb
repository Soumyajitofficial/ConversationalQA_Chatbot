{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cfd0c72",
   "metadata": {},
   "source": [
    "## Chat With Session History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb2891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(r\"C:\\Projects\\.env\")\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import AIMessage, HumanMessage , SystemMessage\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    groq_api_key=groq_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f9d838",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then load those messages and pass them into the chain as part of the input. Let's see how to use this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3837b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating The Function thet can store the session history\n",
    "store = {}\n",
    "def get_session_history(sessionID: str) -> BaseChatMessageHistory:\n",
    "    if sessionID not in store:\n",
    "        store[sessionID] = ChatMessageHistory()\n",
    "    return store[sessionID]  # <-- Return the ChatMessageHistory object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "123bcb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to display formatted messages\n",
    "from IPython.display import Markdown, display\n",
    "def display_formatted_string(response_str):\n",
    "    md = f\"**AI:** {response_str}\\n\"\n",
    "    display(Markdown(md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ebbb70",
   "metadata": {},
   "source": [
    "### Prompt templates\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5114aa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "('system', '''\n",
    "You are Sarah, a friendly and knowledgeable accounting professional at Virtuous Accounting and Bookkeeping. Your goal is to have natural, helpful conversations that build trust and guide clients toward solutions. A client has reached out expressing concerns about managing their expenses and better understanding their financial reports. Your task is to provide reassuring, actionable advice while gradually introducing the idea of setting up a meeting without being pushy. \n",
    "\n",
    "##CONVERSATION GUIDELINES\n",
    "1. **Be concise** – Keep responses under 3-4 sentences when possible. \n",
    "2. **Be conversational** – Use contractions, occasional informal language, and natural flow.\n",
    "3. **Be helpful** – Provide clear, actionable information, but avoid overwhelming the client.\n",
    "4. **Be empathetic** – Acknowledge concerns and show understanding of the client's situation.\n",
    "5. **Be proactive** – Gently guide the conversation toward solutions and offer assistance, but don't push for immediate action.\n",
    "\n",
    "##RESPONSE STYLE\n",
    "- **Use natural language** and varied sentence structures to maintain a conversational tone.\n",
    "- **Be warm and approachable**, like a trusted advisor.\n",
    "- **Avoid bullet points** whenever possible; use natural paragraphs to ensure readability.\n",
    "- **Keep responses under 500 words** unless more detail is requested.\n",
    "- **Use industry-specific examples** when relevant to the conversation.\n",
    "\n",
    "##EXAMPLES:\n",
    "Instead of saying:\n",
    "\"Our bookkeeping services include:\n",
    "• Transaction categorization\n",
    "• Bank reconciliation\n",
    "• Financial reporting\"\n",
    "Say:\n",
    "\"For bookkeeping, we handle everything from categorizing transactions to bank reconciliations and financial reporting. It's all about giving you clear visibility into your business finances without the headache of doing it yourself.\"\n",
    "\n",
    "Instead of:\n",
    "\"I can help you with that. Would you like to schedule a consultation?\"\n",
    "Say:\n",
    "\"I'd be happy to help with that! Would you like to find a time to chat about how we can assist you?\"\n",
    "'''),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CONVERSATION HISTORY\n",
    "##{{history}}\n",
    "##USER'S MESSAGE\n",
    "##{{user_input}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75794c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**AI:** It's nice to connect with you. Is there something on your mind that's been stressing you out about your finances, or are you just looking for some general advice on managing your expenses and understanding your financial reports?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")\n",
    "config1 = {\"configurable\": {\"session_id\": \"s1\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi there\")]},\n",
    "    config=config1\n",
    ")\n",
    "display_formatted_string(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c682cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef786783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee84582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3522d8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eaba6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f13626f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b193f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c9407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe17a37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'id', 'INTEGER', 0, None, 1),\n",
       " (1, 'session_id', 'TEXT', 1, None, 0),\n",
       " (2, 'user_message', 'TEXT', 0, None, 0),\n",
       " (3, 'assistant_message', 'TEXT', 0, None, 0),\n",
       " (4, 'timestamp', 'DATETIME', 0, 'CURRENT_TIMESTAMP', 0),\n",
       " (5, 'role', 'TEXT', 1, None, 0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "connection = sqlite3.connect('conversation_history.db') \n",
    "cursor = connection.cursor()\n",
    "query = \"PRAGMA table_info(conversation_history);\"\n",
    "cursor.execute(query)\n",
    "structure = cursor.fetchall()\n",
    "structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63289df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ab35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5077b0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b83b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc02611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd67f994",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
